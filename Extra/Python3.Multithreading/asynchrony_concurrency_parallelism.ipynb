{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asynchrony, Concurrency, and Parallelism\n",
    "\n",
    "Concurrent Execution: https://docs.python.org/3.8/library/concurrency.html  \n",
    "\n",
    "* Terminology\n",
    "    - ***Global Interpreter Lock (GIL)*** prevents simultaneous Python thread execution (memory management is not thread-safe).\n",
    "    - ***Async coroutines*** overlap operations using cooperative multitasking within a single thread.\n",
    "    - ***Threads*** achieve parallelism using shared memory within a single process.\n",
    "    - ***Processes*** achieve parallelism using isolated process memory within a single Machine.\n",
    "    - ***Distributed computing*** achieve parallelism using a server cluster on a single network.\n",
    "* Modules\n",
    "    - Cooperative coroutines with the ```asyncio``` module (single thread in single process)\n",
    "    - Preemptive multithreading with the ```threading``` module (multiple threads in single process)\n",
    "    - Multiprocessing with the ```multiprocessing``` module (multiple threads in multiple processes)\n",
    "* Classes\n",
    "    - The ```threading.Thread``` Class\n",
    "    - The ```threading.Lock``` Class\n",
    "    - The ```threading.local``` Class\n",
    "    - The ```threading.Event``` Class\n",
    "    - The ```threading.Condition``` Class\n",
    "    - The ```multiprocessing.Process``` class\n",
    "    - The ```multiprocessing.Pool``` class\n",
    "    - The ```queue.Queue``` class (defined in the ```queue``` module) implements a multi-producer/multi-consumer queue. It allows multiple threads to safely exchange messages using locking semantics.\n",
    "\n",
    "* Concepts\n",
    "    - Concurrency vs asynchrony vs parallelism\n",
    "    - Preemptive multitasking vs cooperative multitasking\n",
    "    - Multi-core computing vs distributed computing\n",
    "    - Coroutines and Tasks (async programming)\n",
    "    - A ```Queue``` supports FIFO message-based communication (two types: threads and processes)\n",
    "    - Distribute parallel computing load over multiple processor cores\n",
    "    - Synchronous vs asynchronous parallel processing: The ```asyncio``` module\n",
    "    - Daemon threads automatically terminate when the main thread ends. Daemon threads do not have the ability to keep the process running on thier own. Daemon threads are used to run in the background without the need to worry about explicitly shutting them down.\n",
    "    - Embarrassingly parallel means a problem can be broken down into sub-units of work that run simultaniously and independently on multiple processors without overhead due to state sharing and synchronization blocking issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.6\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jupyter core     : 4.6.3\n",
      "jupyter-notebook : 6.0.3\n",
      "qtconsole        : 4.7.2\n",
      "ipython          : 7.13.0\n",
      "ipykernel        : 5.1.4\n",
      "jupyter client   : 6.1.2\n",
      "jupyter lab      : 1.2.6\n",
      "nbconvert        : 5.6.1\n",
      "ipywidgets       : 7.5.1\n",
      "nbformat         : 5.0.4\n",
      "traitlets        : 4.3.3\n"
     ]
    }
   ],
   "source": [
    "!jupyter --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__main__\n"
     ]
    }
   ],
   "source": [
    "print(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Interpreter Lock (GIL)\n",
    "\n",
    "* Used by CPython interpreter to limit execution of Python bytecode to one thread at a time\n",
    "* Only one thread at a time runs Python code while all other threads are sleeping or blocking\n",
    "* Allows for concurrent execution of code (IO bound) but not parallel execution of code (CPU bound)\n",
    "* Makes it easier for the interpreter to be thread safe\n",
    "* Makes it harder to leverage multi-processor machines\n",
    "* Realeased by some extension modules while doing computationally intensive tasks (numpy)\n",
    "* Always released when doing I/O\n",
    "* The multiprocessing package can run on multiple processors bypassing GIL limitations\n",
    "* NOTE: You can still write Python code that runs concurrently or in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ```asyncio``` Module (```async``` and ```await```)\n",
    "\n",
    "* Async coroutines overlap operations using cooperative multitasking within a single thread.\n",
    "* The ```asyncio``` package provides an API for running and managing asynchronous coroutines\n",
    "* The ```async``` and ```await``` keywords that are used to define coroutines\n",
    "* Coroutines are specialized generator functions that can overlap using cooperative multitasking\n",
    "* Note that ```asyncio``` is not based on either multithreading or multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting multi_thread_with_blocking_wait with timeout = 5 seconds\n",
      "Starting multi_thread_with_blocking_wait with timeout = 5 seconds\n",
      "Starting multi_thread_with_blocking_wait with timeout = 5 seconds\n",
      "Ended multi_thread_with_blocking_wait after 4.99961200000007 seconds\n",
      "Ended multi_thread_with_blocking_wait after 4.999661100000026 seconds\n",
      "Ended multi_thread_with_blocking_wait after 4.999636799999962 seconds\n",
      "Total time taken: 5.0 second(s)"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "import time\n",
    "import threading\n",
    "\n",
    "async def asyncio_with_blocking_wait(timeout):\n",
    "    print(f'\\nStarting multi_thread_with_blocking_wait with timeout = {timeout} seconds', end='')\n",
    "    start_time = time.perf_counter()\n",
    "    await asyncio.sleep(timeout)\n",
    "    end_time = time.perf_counter()\n",
    "    print(f'\\nEnded multi_thread_with_blocking_wait after {end_time - start_time} seconds', end='')\n",
    "\n",
    "start = time.perf_counter()\n",
    "task1 = asyncio.create_task(asyncio_with_blocking_wait(5))\n",
    "task2 = asyncio.create_task(asyncio_with_blocking_wait(5))\n",
    "task3 = asyncio.create_task(asyncio_with_blocking_wait(5))\n",
    "await task1\n",
    "await task2\n",
    "await task3\n",
    "end = time.perf_counter()\n",
    "print(f'\\nTotal time taken: {round(end - start, 2)} second(s)', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ```threading``` Module\n",
    "\n",
    "https://docs.python.org/2/library/threading.html\n",
    "\n",
    "* Threads achieve parallelism using shared memory within a single process.\n",
    "* The ```Thread``` class encapsulates a separate thread of execution within the process\n",
    "* Threads share access to the same memory space within the process\n",
    "* Daemon threads\n",
    "* The ```Thread.join()``` method\n",
    "* Race conditions\n",
    "* The ```threading.local``` class supports thread-local data\n",
    "* ```Lock``` Objects are in one of two states: locked or unlocked: ```acquire()``` and ```release()```\n",
    "* Synchronization using locks\n",
    "* Deadlock\n",
    "* The ```Queue``` threading class\n",
    "* Other threading classes:\n",
    "    - ```Condition``` objects ...\n",
    "    - ```Semaphore``` objects ...\n",
    "    - ```Event``` objects ...\n",
    "    - ```Timer``` objects ...\n",
    "    - ```Barrier``` objects ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ``` threading.Thread``` Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread-21Thread-22 1 \n",
      "0\n",
      "Thread-23 2\n",
      "Thread-24Thread-25 4\n",
      " 3\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "def worker(n):\n",
    "    print(threading.currentThread().getName(), n) # note that concurrent output may get interleaved\n",
    "    return\n",
    "\n",
    "for i in range(5):\n",
    "    t = threading.Thread(target=worker, args=(i,))\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subclassing the ```threading.Thread``` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread-26 0\n",
      "Thread-27 1\n",
      "Thread-28Thread-29 3\n",
      " 2\n",
      "Thread-30 4\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "class MyThread(threading.Thread):\n",
    "    def __init__(self, n):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.n = n\n",
    "    def run(self):\n",
    "        print(threading.currentThread().getName(), self.n) # note that concurrent output is interleaved\n",
    "        return\n",
    "\n",
    "for i in range(5):\n",
    "    t = MyThread(i)\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ```threading.Thread.deamon``` Property\n",
    "\n",
    "* Boolean value set to True for a daemon thread or False for a non-daemon thread\n",
    "* Must be set before ```start()``` is called or ```RuntimeError``` is raised\n",
    "* Initial default value is inherited from creating thread\n",
    "* The main thread is not a daemon so threads created in main thread default to False\n",
    "* The process continues to run as long as there are any non-daemon threads still running\n",
    "* The process automatically terminates as soon as there are no non-daemon threads still running\n",
    "* Daemon threads are not able to keep the process running on their own\n",
    "* When the process ends then any running daemon threads are automatically terminated and cleaned up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting daemon\n",
      "Starting non_daemon\n",
      "Exiting non_daemon\n",
      "Exiting daemon (Note: this will print in Jupyter cell, but not when run stand-alone)\n"
     ]
    }
   ],
   "source": [
    "# NOTE: this example does not properly demonstrate daemon threads in Jupyter Noteboook\n",
    "# To see it work as intend, copy/paste this cell into a .py file and run it stand-alone\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def daemon():\n",
    "    print('Starting daemon')\n",
    "    time.sleep(2)\n",
    "    # following print is not displayed since process ends and this daemon was killed in its sleep\n",
    "    print('Exiting daemon (Note: this will print in Jupyter cell, but not when run stand-alone)')\n",
    "\n",
    "def non_daemon():\n",
    "    print('Starting non_daemon')\n",
    "    time.sleep(1)\n",
    "    # following print is displayed since non-daemon thread keeps process running\n",
    "    print('Exiting non_daemon')\n",
    "    \n",
    "d = threading.Thread(name='daemon', target=daemon)\n",
    "d.daemon = True\n",
    "d.start()\n",
    "\n",
    "t = threading.Thread(name='non-daemon', target=non_daemon)\n",
    "t.daemon = False # redundant here since it inherits parent thread value which is Flase in this case)\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ```queue.Queue``` Class\n",
    "https://docs.python.org/3/library/queue.html#module-queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10424 (main thread)\n",
      "5904 Hello\n",
      "5904 42\n",
      "10524 True\n",
      "10524 [7, 7, 7]\n",
      "10412 (5,)\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import queue\n",
    "import time\n",
    "import random\n",
    "\n",
    "def worker():\n",
    "    while True:\n",
    "        time.sleep(random.randint(1, 10)/100)    # simulate variability in execution time\n",
    "        queue_item = q.get()                     # receive a message from the queue\n",
    "        if queue_item is None:                   # if queue is empty then terminate worker thread loop\n",
    "            break\n",
    "        print(threading.get_ident(), queue_item) # display info on thread id and queue item\n",
    "        q.task_done()                            # indicate formerly enqueued message completed\n",
    "\n",
    "print(threading.get_ident(), \"(main thread)\")\n",
    "number_worker_threads = 5\n",
    "q = queue.Queue()\n",
    "threads = []\n",
    "for i in range(number_worker_threads):\n",
    "    t = threading.Thread(target=worker)\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "# send a bunch of messages to the queue\n",
    "for item in [\"Hello\", \"42\", True, [7, 7, 7], (5,)]:\n",
    "    q.put(item)\n",
    "\n",
    "# block until all items in queue have are received and processed\n",
    "q.join()\n",
    "\n",
    "# stop all other worker threads\n",
    "for i in range(number_worker_threads):\n",
    "    q.put(None)\n",
    "    \n",
    "# block until all other threads are complete\n",
    "for t in threads:\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ```threading.Lock``` Class and Race Conditions\n",
    "\n",
    "* A race condition can happen when two or more threads read and write a shared data value or resource\n",
    "* Race condition can cause intermittent data corruption and non-deterministic behavior\n",
    "* Race condition can be very hard to detect, test, and debug\n",
    "* Race condition can be fixed using a synchronization object, such as a lock, at the expense of some performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import threading\n",
    "import random\n",
    "\n",
    "class DataObject:\n",
    "    def __init__(self):\n",
    "        self.x = 0\n",
    "        self.y = 0\n",
    "        self.z = self.x + self.y      # business rule at all times: z = x + y\n",
    "        self._lock = threading.Lock()\n",
    "    def update(self, x, y):\n",
    "        # try commenting out the following statement and verify that corrupted data results\n",
    "        with self._lock: #easier than self._lock.acquire() & self._lock.release()\n",
    "            self.x = x\n",
    "            time.sleep(random.randint(0, 100)/1000)\n",
    "            self.y = y\n",
    "            time.sleep(random.randint(0, 100)/1000)\n",
    "            self.y = y\n",
    "            time.sleep(random.randint(0, 100)/1000)\n",
    "            self.z = self.x + self.y\n",
    "            time.sleep(random.randint(0, 100)/1000)\n",
    "            if self.z == self.x + self.y:\n",
    "                print('-', end=' ')     # good data \n",
    "            else:\n",
    "                print('*', end=' ')     # corrupted data\n",
    "\n",
    "do = DataObject()\n",
    "\n",
    "def foo():\n",
    "    for i in range(0, 20):\n",
    "        new_value = do.update(random.randint(0, 100), random.randint(0, 100))\n",
    "\n",
    "# try commenting out the three lines below that start with t2 and verify no corrupted data results\n",
    "t1 = threading.Thread(target=foo)   # few seconds CPU bound execution\n",
    "t2 = threading.Thread(target=foo)   # few seconds CPU bound execution\n",
    "t1.start()\n",
    "t2.start()\n",
    "t1.join()\n",
    "t2.join()\n",
    "print(\"\\nDone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deadlock Conditions\n",
    "\n",
    "* Deadlock can result when more than one thread attempts to get multiple locks the same time.\n",
    "* All threads wait to obtain locks that are already acquired by another thread and no thread can proceed.\n",
    "* Can be fixed by enforcement of an ordering rule and only allowing multiple locks to be acquired in ascending order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ```threading.local``` Class and Thread Local Storage\n",
    "\n",
    "* Thread local data supports thread specific data (different value for each thread)\n",
    "* Create thread local data as ```threading.local```instance (or subclass) and assign attributes to it\n",
    "\n",
    "```pythhon\n",
    "thread_local_data = threading.local()\n",
    "thread_local_data.x = 1\n",
    "thread_local_data.y = 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 6840 , tls: 42\n",
      "id: 6840 , tls: 358\n",
      "id: 11196 , tls: 43\n",
      "id: 11196 , tls: 801\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import random\n",
    "\n",
    "tls = threading.local() # global variable provides access to data shared by functions in same thread\n",
    "\n",
    "def display_tls_value(tls):\n",
    "    print(\"id:\", threading.get_ident(), \", tls:\", tls.value)    # value depends on thread we are in\n",
    "\n",
    "def thread_function(value):\n",
    "    tls.value = value\n",
    "    display_tls_value(tls)\n",
    "    tls.value = random.randint(1, 1000)\n",
    "    display_tls_value(tls)\n",
    "\n",
    "t1 = threading.Thread(target=thread_function, args=(42,))\n",
    "t1.start()\n",
    "t2 = threading.Thread(target=thread_function, args=(43,))\n",
    "t2.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ```threading.Event``` Class\n",
    "\n",
    "* Used for signaling between threads that an event has occurred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Main thread creating event\n",
      "Main thread creating secondary thread\n",
      "Secondary thread started\n",
      "Main thread setting event\n",
      "Main thread done\n",
      "Secondary thread wait ended (event was set in main thread)"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def wait_for_event(event):\n",
    "    t = threading.currentThread()\n",
    "    print('\\nSecondary thread started', end='')\n",
    "    event_is_set = event.wait()\n",
    "    print('\\nSecondary thread wait ended (event was set in main thread)', end='')\n",
    "\n",
    "print('\\nMain thread creating event', end='')\n",
    "event = threading.Event()\n",
    "print('\\nMain thread creating secondary thread', end='')\n",
    "t = threading.Thread(name='wait_for_event', target=wait_for_event, args=(event,))\n",
    "t.start()\n",
    "time.sleep(3)\n",
    "print('\\nMain thread setting event', end='')\n",
    "event.set()\n",
    "print('\\nMain thread done', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ```threading.Condition``` Class\n",
    "\n",
    "* A Condition object can be used to synchronize threads\n",
    "* The ```threading.Condition.wait()``` method releases the underlying lock then blocks until awakened by notify() or notify_all() call for the same condition variable in another thread\n",
    "* The ```threading.Condition.notifyAll()``` wakes up one thread waiting on this condition (if any)\n",
    "* The ```threading.Condition.notifyAll()``` Wakes up all threads waiting on this condition (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting consumer_thread_1\n",
      "Starting consumer_thread_2\n",
      "Starting producer_thread\n",
      "producer_thread notifying all consumers\n",
      "consumer_thread_2 notified by producer\n",
      "consumer_thread_1 notified by producer\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def consumer(cond):\n",
    "    t = threading.currentThread()\n",
    "    print('Starting', t.getName())\n",
    "    with cond:\n",
    "        cond.wait()\n",
    "        print(t.getName(), 'notified by producer')\n",
    "\n",
    "def producer(cond):\n",
    "    t = threading.currentThread()\n",
    "    print('Starting', t.getName())\n",
    "    with cond:\n",
    "        print(t.getName(), 'notifying all consumers')\n",
    "        cond.notifyAll()\n",
    "\n",
    "condition = threading.Condition()\n",
    "\n",
    "consumer_thread_1 = threading.Thread(name='consumer_thread_1', target=consumer, args=(condition,))\n",
    "consumer_thread_2 = threading.Thread(name='consumer_thread_2', target=consumer, args=(condition,))\n",
    "producer_thread = threading.Thread(name='producer_thread', target=producer, args=(condition,))\n",
    "\n",
    "consumer_thread_1.start()\n",
    "time.sleep(1)\n",
    "consumer_thread_2.start()\n",
    "time.sleep(1)\n",
    "producer_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thread Timing Comparisons\n",
    "* Single thread with blocking wait\n",
    "* Multi thread with blocking wait\n",
    "* Single thread with busy wait\n",
    "* Multi thread with busy wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting single_thread_with_blocking_wait with timeout = 5 seconds\n",
      "Ended single_thread_with_blocking_wait after 5.012447100000001 seconds\n",
      "Starting single_thread_with_blocking_wait with timeout = 5 seconds\n",
      "Ended single_thread_with_blocking_wait after 5.0035498 seconds\n",
      "Starting single_thread_with_blocking_wait with timeout = 5 seconds\n",
      "Ended single_thread_with_blocking_wait after 5.0089393 seconds\n",
      "Total time taken: 15.03 second(s)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def single_thread_with_blocking_wait(timeout):\n",
    "    print(f'\\nStarting single_thread_with_blocking_wait with timeout = {timeout} seconds', end='')\n",
    "    start_time = time.perf_counter()\n",
    "    time.sleep(timeout)\n",
    "    end_time = time.perf_counter()\n",
    "    print(f'\\nEnded single_thread_with_blocking_wait after {end_time - start_time} seconds', end='')\n",
    "\n",
    "start = time.perf_counter()\n",
    "single_thread_with_blocking_wait(5)\n",
    "single_thread_with_blocking_wait(5)\n",
    "single_thread_with_blocking_wait(5)\n",
    "end = time.perf_counter()\n",
    "print(f'\\nTotal time taken: {round(end - start, 2)} second(s)', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting multi_thread_with_blocking_wait with timeout = 5 seconds\n",
      "Starting multi_thread_with_blocking_wait with timeout = 5 seconds\n",
      "Starting multi_thread_with_blocking_wait with timeout = 5 seconds\n",
      "Ended multi_thread_with_blocking_wait after 5.0035834 seconds\n",
      "Ended multi_thread_with_blocking_wait after 5.003803900000001 seconds\n",
      "Ended multi_thread_with_blocking_wait after 5.008586399999999 seconds\n",
      "Total time taken: 5.02 second(s)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import threading\n",
    "\n",
    "def multi_thread_with_blocking_wait(timeout):\n",
    "    print(f'\\nStarting multi_thread_with_blocking_wait with timeout = {timeout} seconds', end='')\n",
    "    start_time = time.perf_counter()\n",
    "    time.sleep(timeout)\n",
    "    end_time = time.perf_counter()\n",
    "    print(f'\\nEnded multi_thread_with_blocking_wait after {end_time - start_time} seconds', end='')\n",
    "\n",
    "start = time.perf_counter()\n",
    "t1 = threading.Thread(target=multi_thread_with_blocking_wait, args=(5,))\n",
    "t2 = threading.Thread(target=multi_thread_with_blocking_wait, args=(5,))\n",
    "t3 = threading.Thread(target=multi_thread_with_blocking_wait, args=(5,))\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "t1.join()\n",
    "t2.join()\n",
    "t3.join()\n",
    "end = time.perf_counter()\n",
    "print(f'\\nTotal time taken: {round(end - start, 2)} second(s)', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting single_thread_with_busy_wait with n = 10000\n",
      "Ended single_thread_with_busy_wait after 5.681020400000001 seconds\n",
      "Starting single_thread_with_busy_wait with n = 10000\n",
      "Ended single_thread_with_busy_wait after 5.800952900000002 seconds\n",
      "Starting single_thread_with_busy_wait with n = 10000\n",
      "Ended single_thread_with_busy_wait after 5.1858536000000015 seconds\n",
      "Total time taken: 16.67 second(s)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def single_thread_with_busy_wait(n):\n",
    "    print(f'\\nStarting single_thread_with_busy_wait with n = {n}', end='')\n",
    "    start_time = time.perf_counter()\n",
    "    count = 1\n",
    "    for i in range(1, n):\n",
    "        for j in range(1, n):\n",
    "            count = i + j          # pointless busy work for CPU to chew on\n",
    "    end_time = time.perf_counter()\n",
    "    print(f'\\nEnded single_thread_with_busy_wait after {end_time - start_time} seconds', end='')\n",
    "\n",
    "start = time.perf_counter()\n",
    "single_thread_with_busy_wait(10000) # few seconds CPU bound execution\n",
    "single_thread_with_busy_wait(10000) # few seconds CPU bound execution\n",
    "single_thread_with_busy_wait(10000) # few seconds CPU bound execution\n",
    "end = time.perf_counter()\n",
    "print(f'\\nTotal time taken: {round(end - start, 2)} second(s)', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Running one seperate thread:\n",
      "Starting multi_thread_with_busy_wait with n = 10000\n",
      "Ended multi_thread_with_busy_wait after 5.704671859741211 seconds\n",
      "Total time taken: 5.72 second(s)\n",
      "***Running three spereate threads at the same time:\n",
      "Starting multi_thread_with_busy_wait with n = 10000\n",
      "Starting multi_thread_with_busy_wait with n = 10000\n",
      "Starting multi_thread_with_busy_wait with n = 10000\n",
      "Ended multi_thread_with_busy_wait after 15.898375272750854 seconds\n",
      "Ended multi_thread_with_busy_wait after 17.480390787124634 seconds\n",
      "Ended multi_thread_with_busy_wait after 17.56799864768982 seconds\n",
      "Total time taken: 17.64 second(s)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import threading\n",
    "\n",
    "def multi_thread_with_busy_wait(n):\n",
    "    print(f'\\nStarting multi_thread_with_busy_wait with n = {n}', end='')\n",
    "    start_time = time.time()\n",
    "    count = 1\n",
    "    for i in range(1, n):\n",
    "        for j in range(1, n):\n",
    "            count = i + j          # pointless busy work for CPU to chew on\n",
    "    end_time = time.time()\n",
    "    print(f'\\nEnded multi_thread_with_busy_wait after {end_time - start_time} seconds', end='')\n",
    "\n",
    "print('\\n***Running one seperate thread:', end='')\n",
    "start = time.perf_counter()\n",
    "t0 = threading.Thread(target=multi_thread_with_busy_wait, args=(10000,))  # few seconds CPU bound execution\n",
    "t0.start()\n",
    "t0.join()\n",
    "end = time.perf_counter()\n",
    "print(f'\\nTotal time taken: {round(end - start, 2)} second(s)', end='')\n",
    "\n",
    "print('\\n***Running three spereate threads at the same time:', end='')\n",
    "start = time.perf_counter()\n",
    "t1 = threading.Thread(target=multi_thread_with_busy_wait, args=(10000,))  # few seconds CPU bound execution\n",
    "t2 = threading.Thread(target=multi_thread_with_busy_wait, args=(10000,))  # few seconds CPU bound execution\n",
    "t3 = threading.Thread(target=multi_thread_with_busy_wait, args=(10000,))  # few seconds CPU bound execution\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "t1.join()\n",
    "t2.join()\n",
    "t3.join()\n",
    "end = time.perf_counter()\n",
    "print(f'\\nTotal time taken: {round(end - start, 2)} second(s)', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ```multiprocessing``` Module\n",
    "\n",
    "* Processes achieve parallelism using isolated process memory within a single Machine.\n",
    "* Uses processes instead of threads that can take better advantage of multi-core computers\n",
    "* Good for CPU-intensive parallelism (avoids GIL blocking) but adds multi-process overhead\n",
    "* The ```Process``` class\n",
    "* The ```Pool``` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  8\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ```multiprocessing.Process``` Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: This example will not print to Jupyter cell output because it is from another process. To see it work properly, edit the files ```mymodule.py``` and ```main.py``` and run ```main.py``` directly in the python interpreter at the command prompt instead and then see the result in the standard output.\n",
    "\n",
    "```python\n",
    "# mymodule.py\n",
    "def say_hello(name):\n",
    "    print('hello', name)\n",
    "```\n",
    "\n",
    "```python\n",
    "# main.py\n",
    "import multiprocessing\n",
    "import mymodule\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p = multiprocessing.Process(target=mymodule.say_hello, args=('Sally',))\n",
    "    p.start()\n",
    "    p.join()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ```multiprocessing.Queue``` Class\n",
    "* ```multiprocessing.Queue``` class supports multi-process queues rather than multi-thread queues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# toy example of multiprocessing.Queue that involves only one thread talking to itself in one process \n",
    "import multiprocessing as mp\n",
    "\n",
    "queue = mp.Queue()\n",
    "queue.put(1)\n",
    "queue.put(2)\n",
    "queue.put(3)\n",
    "print(queue.get())\n",
    "print(queue.get())\n",
    "print(queue.get())\n",
    "queue.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a message sent from worker_process.\n"
     ]
    }
   ],
   "source": [
    "# More interesting example of multiprocessing.Queue that involves two threads in two processes talking\n",
    "# NOTE:\n",
    "# mymodule.py (has to be in a physical .py file rather than in a local Jupyter cell)\n",
    "#class QueueMessageObject(object):\n",
    "#    def __init__(self, value):\n",
    "#        self.value = value\n",
    "#    def display(self):\n",
    "#        print(self.value)\n",
    "#\n",
    "#def worker_process(queue):\n",
    "#    queue.put(QueueMessageObject('This is a message sent from worker_process.'))\n",
    "\n",
    "import multiprocessing as mp\n",
    "import mymodule as mm\n",
    "\n",
    "# Create queue, start process with queue, read and display message from queue\n",
    "queue = mp.Queue()\n",
    "process = mp.Process(target=mm.worker_process, args=(queue,))\n",
    "process.start()\n",
    "queue.get().display()\n",
    "\n",
    "queue.close()       # clean up queue resources\n",
    "queue.join_thread() # clean up associated monitoring thread resources\n",
    "process.join()      # wait for other process to terminate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing Timing Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting multiprocessing_with_busy_wait with n = 10000\n",
      "Starting multiprocessing_with_busy_wait with n = 10000\n",
      "Starting multiprocessing_with_busy_wait with n = 10000\n",
      "Ended multiprocessing_with_busy_wait after {'delta_time': 7.142707499999999} seconds\n",
      "Ended multiprocessing_with_busy_wait after {'delta_time': 7.0401701999999995} seconds\n",
      "Ended multiprocessing_with_busy_wait after {'delta_time': 7.1995857} seconds\n",
      "Total time taken: 7.35 second(s)"
     ]
    }
   ],
   "source": [
    "# NOTE:\n",
    "# mymodule.py (has to be in a physical .py file rather than in a local Jupyter cell)\n",
    "#def multiprocessing_with_busy_wait(n, queue):\n",
    "#    start_time = time.perf_counter()\n",
    "#    count = 1\n",
    "#    for i in range(1, n):\n",
    "#        for j in range(1, n):\n",
    "#            count = i + j          # pointless busy work for CPU to chew on\n",
    "#    end_time = time.perf_counter()\n",
    "#    if queue is not None:\n",
    "#        ret = queue.get()\n",
    "#        ret['delta_time'] = end_time - start_time\n",
    "#        queue.put(ret)\n",
    "    \n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import mymodule\n",
    "\n",
    "print(f'\\nStarting multiprocessing_with_busy_wait with n = {10000}', end='')\n",
    "queue1 = mp.Queue()\n",
    "queue1.put({'delta_time': 0})\n",
    "p1 = mp.Process(target=mymodule.multiprocessing_with_busy_wait, args=(10000, queue1)) # few seconds CPU bound execution\n",
    "print(f'\\nStarting multiprocessing_with_busy_wait with n = {10000}', end='')\n",
    "queue2 = mp.Queue()\n",
    "queue2.put({'delta_time': 0})\n",
    "p2 = mp.Process(target=mymodule.multiprocessing_with_busy_wait, args=(10000, queue2)) # few seconds CPU bound execution\n",
    "print(f'\\nStarting multiprocessing_with_busy_wait with n = {10000}', end='')\n",
    "queue3 = mp.Queue()\n",
    "queue3.put({'delta_time': 0})\n",
    "p3 = mp.Process(target=mymodule.multiprocessing_with_busy_wait, args=(10000, queue3)) # few seconds CPU bound execution\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "p1.start()\n",
    "p2.start()\n",
    "p3.start()\n",
    "\n",
    "p1.join()\n",
    "p2.join()\n",
    "p3.join()\n",
    "\n",
    "print(f'\\nEnded multiprocessing_with_busy_wait after {queue1.get()} seconds', end='')\n",
    "print(f'\\nEnded multiprocessing_with_busy_wait after {queue2.get()} seconds', end='')\n",
    "print(f'\\nEnded multiprocessing_with_busy_wait after {queue3.get()} seconds', end='')\n",
    "\n",
    "end = time.perf_counter()\n",
    "print(f'\\nTotal time taken: {round(end - start, 2)} second(s)', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ```multiprocessing.Pool``` Class\n",
    "* ```Pool.map()```\n",
    "* ```Pool.apply()```\n",
    "* ```Pool.starmap()```\n",
    "* ```Pool.map_async()```\n",
    "* ```Pool.apply_async()```\n",
    "* ```Pool.starmap_async()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16, 25]\n"
     ]
    }
   ],
   "source": [
    "# Simple example using Pool.map() to distribute function over processes on multiple CPU cores\n",
    "\n",
    "# NOTE:\n",
    "# mymodule.py (has to be in a physical .py file rather than in a local Jupyter cell)\n",
    "# def mysquare(x):\n",
    "#    return x*x\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import mymodule\n",
    "\n",
    "with Pool(5) as p:\n",
    "    print(p.map(mymodule.mysquare, [1, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing CPU Load in Performance Monitor: Threads vs Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Sequential (no paralleization)\n",
    "\n",
    "def single_thread_with_busy_wait(n):\n",
    "    count = 1\n",
    "    for i in range(1, n):\n",
    "        for j in range(1, n):\n",
    "            count = i + j          # pointless busy work for CPU to chew on\n",
    "\n",
    "for i in range(0, mp.cpu_count()):\n",
    "    single_thread_with_busy_wait(6000) # few seconds CPU bound execution\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential (no paralleization)\n",
    "![# Sequential (no paralleization)](img/average_sequential.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Parallelizing using Pool.map()\n",
    "\n",
    "import multiprocessing as mp\n",
    "import mymodule\n",
    "\n",
    "# NOTE:\n",
    "# mymodule.py (has to be in a physical .py file rather than in a local Jupyter cell)\n",
    "#def multiprocessing_with_busy_wait(n, queue):\n",
    "#    start_time = time.perf_counter()\n",
    "#    count = 1\n",
    "#    for i in range(1, n):\n",
    "#        for j in range(1, n):\n",
    "#            count = i + j          # pointless busy work for CPU to chew on\n",
    "#    end_time = time.perf_counter()\n",
    "#    if queue is not None:\n",
    "#        ret = queue.get()\n",
    "#        ret['delta_time'] = end_time - start_time\n",
    "#        queue.put(ret)\n",
    "\n",
    "pool = mp.Pool(mp.cpu_count()) # Establish multiprocessing pool\n",
    "inputs = []\n",
    "for i in range(0, mp.cpu_count()):\n",
    "    inputs.append(6000)\n",
    "pool.map(mymodule.multiprocessing_with_busy_wait, inputs) # Map function on pool\n",
    "pool.close() # Close pool\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelizing with the Pool.map() Function\n",
    "![# Sequential (no paralleization)](img/average_pool_map.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
